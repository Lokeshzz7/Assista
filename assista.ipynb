{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaba04f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_core langchain_groq langchain_community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1499173",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display , Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af56d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "  query: str\n",
    "  category: str\n",
    "  sentiment: str\n",
    "  response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d704e65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key = \"groq_api_key\",\n",
    "    model_name = \"llama-3.3-70b-versatile\"\n",
    ")\n",
    "result = llm.invoke(\"What is Life\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b723d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def categorize(state: State) -> State:\n",
    "  \"Technical, Billing, General\"\n",
    "  prompt = ChatPromptTemplate.from_template(\n",
    "      \"Please categorize the following customer query into one of the following categories: \"\n",
    "      \"'Technical', 'Billing', or 'General'. Customer query: {query}\"\n",
    "  )\n",
    "  \n",
    "  chain = prompt | llm\n",
    "  category = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "  return {\"category\": category}\n",
    "\n",
    "def analyze_sentiment(state: State) -> State:\n",
    "  prompt = ChatPromptTemplate.from_template(\n",
    "      \"Determine the sentiment of the following customer query. \"\n",
    "      \"Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}\"\n",
    "  )\n",
    "  chain = prompt | llm\n",
    "  sentiment = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "  return {\"sentiment\": sentiment}\n",
    "\n",
    "def handle_technical(state: State) -> State:\n",
    "  prompt = ChatPromptTemplate.from_template(\n",
    "      \"Provide a detailed technical support response for this query: {query}\"\n",
    "  )\n",
    "  chain = prompt | llm\n",
    "  response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "  return {\"response\": response}\n",
    "\n",
    "def handle_billing(state: State) -> State:\n",
    "  prompt = ChatPromptTemplate.from_template(\n",
    "      \"Please provide a response to the following billing-related customer query: {query}\"\n",
    "  )\n",
    "  chain = prompt | llm\n",
    "  response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "  return {\"response\": response}\n",
    "\n",
    "def handle_general(state: State) -> State:\n",
    "  prompt = ChatPromptTemplate.from_template(\n",
    "      \"Provide a general customer support response for the following query: {query}\"\n",
    "  )\n",
    "  chain = prompt | llm\n",
    "  response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "  return {\"response\": response}\n",
    "\n",
    "def escalate(state: State) -> State:\n",
    "  return {\"response\": \"This query has been escalated to a human agent due to its negative sentiment.\"}\n",
    "\n",
    "def route_query(state: State) -> State:\n",
    "  if state[\"sentiment\"] == \"Negative\":\n",
    "    return \"escalate\"\n",
    "  elif state[\"category\"] == \"Technical\":\n",
    "    return \"handle_technical\"\n",
    "  elif state[\"category\"] == \"Billing\":\n",
    "    return \"handle_billing\"\n",
    "  else:\n",
    "    return \"handle_general\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3f65b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"categorize\", categorize)\n",
    "workflow.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "workflow.add_node(\"handle_technical\", handle_technical)\n",
    "workflow.add_node(\"handle_billing\", handle_billing)\n",
    "workflow.add_node(\"handle_general\", handle_general)\n",
    "workflow.add_node(\"escalate\", escalate)\n",
    "\n",
    "workflow.add_edge(\"categorize\", \"analyze_sentiment\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_sentiment\",\n",
    "    route_query,{\n",
    "        \"handle_technical\" : \"handle_technical\",\n",
    "        \"handle_billing\" :  \"handle_billing\",\n",
    "        \"handle_general\" : \"handle_general\",\n",
    "        \"escalate\": \"escalate\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"handle_technical\", END)\n",
    "workflow.add_edge(\"handle_billing\", END)\n",
    "workflow.add_edge(\"handle_general\", END)\n",
    "workflow.add_edge(\"escalate\", END)\n",
    "\n",
    "workflow.set_entry_point(\"categorize\")\n",
    "\n",
    "app  = workflow.compile()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
